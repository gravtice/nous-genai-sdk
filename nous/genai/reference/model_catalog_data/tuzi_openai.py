from __future__ import annotations

MODELS: list[str] = [
    "computer-use-preview",
    "gpt-3.5-turbo",
    "gpt-3.5-turbo-16k",
    "gpt-3.5-turbo-instruct",
    "gpt-4",
    "gpt-4-32k",
    "gpt-4-turbo",
    "gpt-4-vision-preview",
    "gpt-4.1",
    "gpt-4.1-mini",
    "gpt-4.1-nano",
    "gpt-4.5-preview",
    "gpt-4o",
    "gpt-4o-audio-preview",
    "gpt-4o-mini",
    "gpt-4o-mini-audio-preview",
    "gpt-4o-mini-realtime-preview",
    "gpt-4o-mini-search-preview",
    "gpt-4o-realtime-preview",
    "gpt-4o-search-preview",
    "gpt-5",
    "gpt-5-codex",
    "gpt-5-mini",
    "gpt-5-nano",
    "gpt-5-pro",
    "gpt-5.1",
    "gpt-5.1-codex",
    "gpt-5.1-codex-max",
    "gpt-5.1-codex-mini",
    "gpt-5.2",
    "gpt-5.2-pro",
    "gpt-oss-120b",
    "GPT-OSS-20B",
    "MiniMax-Text-01",
    "o1",
    "o1-mini",
    "o1-pro",
    "o3",
    "o3-mini",
    "o3-mini-high",
    "o3-mini-low",
    "o3-mini-medium",
    "o3-pro",
    "o4-mini",
    "openai/gpt-oss-120b",
    "openai/gpt-oss-20b",
    "distil-whisper-large-v3-en",
    "gpt-4o-mini-transcribe",
    "gpt-4o-transcribe",
    "gpt-4o-transcribe-diarize",
    "whisper-1",
    "whisper-large-v3",
    "whisper-large-v3-turbo",
    "dall-e-2",
    "dall-e-3",
    "FLUX.1-Kontext-pro",
    "gpt-4o-image",
    "gpt-image-1",
    "gpt-image-1.5",
    "sora-2",
    "sora-2-pro",
    "gpt-4o-mini-tts",
    "tts-1",
    "tts-1-hd",
    "doubao-embedding-large-text-240915",
    "doubao-embedding-text-240715",
    "text-embedding-004",
    "text-embedding-3-large",
    "text-embedding-3-small",
    "text-embedding-ada-002",
    "text-embedding-v4",
]
